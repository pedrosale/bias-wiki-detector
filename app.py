import streamlit as st, pandas as pd
from src.wiki_fetch import buscar_artigos
from src.detector import analisar_artigos
from datetime import datetime

st.set_page_config(page_title="Bias Wiki Detector", layout="wide")
st.title("üß† Bias Wiki Detector")

st.markdown("""
<div style="background-color:#f0f2f6;padding:10px;border-left:5px solid #999;">
O detector pesquisa at√© <b>50 artigos da Wikip√©dia</b> cujo t√≠tulo cont√©m o termo informado, 
consulta a <i>MediaWiki&nbsp;API</i> para obter a <b>data da √∫ltima edi√ß√£o</b> e analisa os <b>N artigos mais recentes</b>.<br>
‚ö†Ô∏è Se a data estiver indispon√≠vel para algum artigo, ele √© listado ap√≥s os que possuem data v√°lida.
</div>

<div style="margin-top:15px; margin-bottom:25px;">
<a href="https://github.com/pedrosale/bias-wiki-detector/blob/main/README.md" target="_blank">
üìò Veja aqui as defini√ß√µes dos tipos de vi√©s analisados pela ferramenta</a>.
</div>
""", unsafe_allow_html=True)

# Entrada
termo = st.text_input("üîç Termo de busca", value="intelig√™ncia artificial")
qtd = st.number_input("üìÑ Defina N", 1, 50, 3)
executar = st.button("Analisar")

# Processamento
if "df_final" not in st.session_state or executar:
    with st.spinner("üîé Buscando artigos‚Ä¶"):
        df_raw = buscar_artigos(termo, qtd)

    if df_raw.empty:
        st.warning("Nenhum artigo encontrado com esse termo no t√≠tulo.")
        st.stop()

    st.success(f"{len(df_raw)} artigos encontrados.")
    st.dataframe(df_raw[["Artigo", "Link", "data_ultima_edicao"]], use_container_width=True)

    with st.spinner("ü§ñ Rodando an√°lise de vi√©s (OpenAI)‚Ä¶"):
        df_final = analisar_artigos(df_raw.head(qtd))

    st.session_state.df_final = df_final
    st.session_state.df_raw = df_raw

# Exibi√ß√£o
if "df_final" in st.session_state:
    df_final = st.session_state.df_final
    df_raw = st.session_state.df_raw

    st.success("An√°lise conclu√≠da!")

    artigos = df_final["Artigo"].unique()
    escolhido = st.selectbox("üìë Selecione um artigo para ver a an√°lise completa:", artigos)

    df_artigo = df_final[df_final["Artigo"] == escolhido]
    link = df_artigo["Link"].iloc[0]
    st.markdown(f"### üìÑ [{escolhido}]({link})", unsafe_allow_html=True)

    for _, row in df_artigo.iterrows():
        st.markdown("---")

        with st.expander("üî¥ Vi√©s Tendencioso"):
            st.markdown(f"**Trecho:** {row.get('Trecho (Tendencioso)', '')}")
            st.markdown(f"**Tipo de Vi√©s:** {row.get('Tipo de Vi√©s', '')}")
            st.markdown(f"**Explica√ß√£o:** {row.get('Explica√ß√£o (Vi√©s)', '')}")
            st.markdown(f"**Reescrita:** {row.get('Reescrita (Vi√©s)', '')}")

        with st.expander("üü† Opini√£o Disfar√ßada"):
            st.markdown(f"**Trecho:** {row.get('Trecho (Opini√£o disfar√ßada)', '')}")
            st.markdown(f"**Motivo:** {row.get('Motivo (Opini√£o)', '')}")
            st.markdown(f"**Reescrita:** {row.get('Reescrita (Opini√£o)', '')}")

        with st.expander("üü° Aus√™ncia de Contraponto"):
            st.markdown(f"**Tema Ausente:** {row.get('Tema ausente', '')}")
            st.markdown(f"**Import√¢ncia do Contraponto:** {row.get('Import√¢ncia do Contraponto', '')}")
            st.markdown(f"**Sugest√£o de Inclus√£o:** {row.get('Sugest√£o de Inclus√£o', '')}")

    # üì§ Exporta√ß√£o CSV
    csv = df_final.to_csv(index=False).encode("utf-8")
    st.download_button("‚¨áÔ∏è Baixar CSV", csv, "bias_report.csv", mime="text/csv")

    # üì§ Exporta√ß√£o HTML
    if st.button("üìÑ Gerar relat√≥rio"):
        html = f"""
        <html><head><meta charset="utf-8"><title>Bias Report</title></head><body>
        <h1>Bias Wiki Detector - Relat√≥rio</h1>
        <p>Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        """

        for artigo in df_final["Artigo"].unique():
            html += f"<h2>{artigo}</h2>"
            sub = df_final[df_final["Artigo"] == artigo]
            for _, row in sub.iterrows():
                html += "<hr>"
                html += f"<p><b>Trecho (Tendencioso):</b> {row.get('Trecho (Tendencioso)', '')}<br>"
                html += f"<b>Tipo:</b> {row.get('Tipo de Vi√©s', '')}<br>"
                html += f"<b>Explica√ß√£o:</b> {row.get('Explica√ß√£o (Vi√©s)', '')}<br>"
                html += f"<b>Reescrita:</b> {row.get('Reescrita (Vi√©s)', '')}</p>"

                html += f"<p><b>Trecho (Opini√£o):</b> {row.get('Trecho (Opini√£o disfar√ßada)', '')}<br>"
                html += f"<b>Motivo:</b> {row.get('Motivo (Opini√£o)', '')}<br>"
                html += f"<b>Reescrita:</b> {row.get('Reescrita (Opini√£o)', '')}</p>"

                html += f"<p><b>Tema ausente:</b> {row.get('Tema ausente', '')}<br>"
                html += f"<b>Import√¢ncia:</b> {row.get('Import√¢ncia do Contraponto', '')}<br>"
                html += f"<b>Sugest√£o:</b> {row.get('Sugest√£o de Inclus√£o', '')}</p>"

        html += "</body></html>"

        st.download_button(
            "‚¨áÔ∏è Baixar relat√≥rio",
            html,
            file_name="bias_report.html",
            mime="text/html"
        )
